import org.apache.spark.sql.SparkSession
import org.apache.log4j.Logger
import org.apache.log4j.Level


object SparkSqlTest {
  def main(args: Array[String]): Unit = {
    
    Logger.getLogger("org").setLevel(Level.ERROR)
    val spark = SparkSession.builder.
    master("local").appName("Simple Application").
    getOrCreate()
    
    val empDF=spark.read.option("header","true").
    csv("file:///home/hadoop/YARNBOX/WORKSPACES/Sept2016WEBatch_GitRepo/SET2/MapReduceCode/Joins-MapReduce/input/emp")
    empDF.printSchema()
    
    val deptDF=spark.read.
    csv("file:///home/hadoop/YARNBOX/WORKSPACES/Sept2016WEBatch_GitRepo/SET2/MapReduceCode/Joins-MapReduce/input/dept").
    toDF("deptid","deptname")
    deptDF.printSchema()
    
    empDF.createOrReplaceTempView("t_emp")
    deptDF.createOrReplaceTempView("t_dept")
    
    spark.sql("select * from t_emp left join t_dept on t_emp.deptid=t_dept.deptid").show
    
    
    
        
    
  }
}