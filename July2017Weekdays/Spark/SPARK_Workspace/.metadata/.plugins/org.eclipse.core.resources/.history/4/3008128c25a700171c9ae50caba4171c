import org.apache.spark.sql.SparkSession
import org.apache.log4j.Logger
import org.apache.log4j.Level


object SparkSqlTest {
  def main(args: Array[String]): Unit = {
    
    Logger.getLogger("org").setLevel(Level.ERROR)
    val spark = SparkSession.builder.
    master("local").appName("Simple Application").
    getOrCreate()
    
    val empDF=spark.read.option("header","true").
    csv("/home/hadoop/YARNBOX/WORKSPACES/Sept2016WEBatch_GitRepo/SET2/MapReduceCode/Joins-MapReduce/input/emp")
    empDF.printSchema()
    
    val deptDF=spark.read.option("header","true").
    csv("/home/hadoop/YARNBOX/WORKSPACES/Sept2016WEBatch_GitRepo/SET2/MapReduceCode/Joins-MapReduce/input/dept")
    deptDF.printSchema()
    
    
        
    
  }
}