import org.apache.spark.sql.SparkSession


object SparkSqlTest {
  def main(args: Array[String]): Unit = {
    
    val spark = SparkSession.master("local").builder.appName("Simple Application").getOrCreate()
    
    val empDF=spark.read.option("header","true").
    csv("/home/hadoop/YARNBOX/WORKSPACES/Sept2016WEBatch_GitRepo/SET2/MapReduceCode/Joins-MapReduce/input/emp")
    empDF.printSchema()
        
    
  }
}