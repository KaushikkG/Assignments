import org.apache.spark.SparkContext


object WordCount {
  def main(args: Array[String]): Unit = {
    val sc=new SparkContext("local[*]","WordCount")
    //sc.setLogLevel(logLevel)
   val input=sc.textFile(args(0))
   val res=input.flatMap(line=>line.split(" ")).
   map(word=>(word,1)).
   reduceByKey((v1,v2)=>v1+v2)
   res.foreach(println)
   
    
   
  }
  
}