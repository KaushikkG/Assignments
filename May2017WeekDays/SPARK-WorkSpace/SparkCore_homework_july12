Date July 12th 2017
Movie lens::
-------------------
Each year How many movies released? sort the data
dataset, how many years preset..
--------------------------------------------

take movies dataset, extract year from..
 each year,
-------------------------------
Scala IDE
--------------------------------------------------
Home work

REPL:::::
1) run the WC on large file ->300MB 
	-> how many partitions getting created? WHY?
	-> Use GroupByKey and ReduceByKey to get the same result->
	 which is better

2) Top Ten most viewed movies with their names (Ascending or des)
	take the ratings data and take the movies data
	first mvid,count then take the top 10, then do the join with movie names..
	filter the resultset

3) solve the above:: 
	i) take data from Local FS, ooutput into localFS
	ii) Integrate spark with HDFS-> take data from HDFS and OP into HDFS
	iii) Develop it as Spark Application -> IDE, run it in standalone scheduler
	iv) Run this spark application using yarn sheduler
-----------------------------------------------
4) All above programs using SPakr SQL::::
 i) How to do Optimization
  ii) Broadcast the data (mapside joins)

------------------------------------------------

input.flatMap(line=>line.split(" ")).map(x=>(x,1)).reduceByKey(_ + _).saveAsTextFile("wc_r")


 input.flatMap(line=>line.split(" "))
.map(x=>(x,1))
.groupByKey()
.map(x=> (x._1,x._2.size))
.saveAsTextFile("wc_g")


#export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

spark-submit --master yarn \
--deploy-mode cluster \
--class MovieLens \
--name "SampleMVlens" \
--conf spark.driver.port=4678 \
/home/hadoop/Desktop/mv.jar \
file:///home/hadoop/Music/Classes/MovieLens-Work-SPARK/ml-1m/movies.dat \
/mv_out \

-------------------------------------------------
Spark 2.x -> Data sets and SQL
val ratings=spark.read.textFile("ratings.dat")
val mv_rating=ratings.map(x=>{( x.split("::")(1),x.split("::")(2))})

val mvDF=mv_rating.toDF("mvname":String,"rating":String)

mvDF.createOrReplaceTempView("mvratings")

spark.sql("select avg(rating) avgrating,mvname,count(rating) numratings from mvratings group by mvname order by  avgrating desc ").show()



---------------------------------------------------

 val users=spark.read.textFile("file:////home/hadoop/Music/Classes/MovieLens-Work-SPARK/ml-1m/users.dat")

val users1=users.map(line=>(line.split("::")(0).toInt,line.split("::")(1),line.split("::")(2).toInt))

val uDF=users1.toDF("id":String,"gender":String,"age":String)

uDF.createOrReplaceTempView("users")
uDF.write.saveAsTable("hivepractice.users")

uDF.write.orc("/userORC")
spark.read.orc("/userORC")
res17: org.apache.spark.sql.DataFrame = [id: int, gender: string ... 1 more field]


